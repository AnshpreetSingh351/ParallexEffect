<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>Invisible Face-Tracking Monkey</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <script type="importmap">
{
  "imports": {
    "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
    "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
  }
}
</script>

  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      font-family: 'Inter', sans-serif;
    }

    body {
      background: #020305;
      color: #fff;
      overflow: hidden;
    }

    canvas {
      position: fixed;
      inset: 0;
      width: 100%;
      height: 100%;
      z-index: 0;
    }

    /* Hidden video element - required for tracking but not displayed */
    #video {
      position: absolute;
      width: 1px;
      height: 1px;
      opacity: 0;
      pointer-events: none;
    }

    .overlay {
      position: fixed;
      inset: 0;
      pointer-events: none;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
      z-index: 10;
    }

    .title {
      font-size: clamp(2.5rem, 8vw, 6rem);
      letter-spacing: 0.5em;
      font-weight: 900;
      text-transform: uppercase;
      background: linear-gradient(to bottom, #ffffff, #444);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      opacity: 0.6;
    }
  </style>
</head>

<body>

  <video id="video" autoplay playsinline></video>
  <canvas id="c"></canvas>

  <div class="overlay">
    <div class="title">MONKEY</div>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>

  <script type="module">
    import * as THREE from "three";
    import { GLTFLoader } from "three/addons/loaders/GLTFLoader.js";

    // --- 1. THREE.JS SETUP ---
    const canvas = document.getElementById("c");
    const renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.toneMapping = THREE.ACESFilmicToneMapping;

    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(35, window.innerWidth / window.innerHeight, 0.1, 100);
    camera.position.set(0, 0, 6.5);

    scene.add(new THREE.AmbientLight(0xffffff, 0.8));
    const l1 = new THREE.PointLight(0x00a2ff, 25); l1.position.set(-5, 2, 2); scene.add(l1);
    const l2 = new THREE.PointLight(0xff00d4, 25); l2.position.set(5, -2, 2); scene.add(l2);

    let monkey = null;
    new GLTFLoader().load('Monkey.glb', (gltf) => {
      monkey = gltf.scene;
      const box = new THREE.Box3().setFromObject(monkey);
      const center = box.getCenter(new THREE.Vector3());
      monkey.position.sub(center);
      scene.add(monkey);
      monkey.scale.set(1.9, 1.9, 1.9);
    });

    // --- 2. HIDDEN FACE TRACKING ---
    const video = document.getElementById('video');
    let faceRotation = { x: 0, y: 0 };

    async function setupCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      return new Promise((resolve) => { video.onloadedmetadata = () => resolve(video); });
    }

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults((results) => {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        const nose = landmarks[1];

        // Tracking logic: Flip the direction so it mimics a mirror
        faceRotation.y = (nose.x - 0.5) * -2.5;
        faceRotation.x = (nose.y - 0.5) * 2.0;
      }
    });

    async function start() {
      await setupCamera();
      // Start tracking loop
      const processFrame = async () => {
        await faceMesh.send({ image: video });
        requestAnimationFrame(processFrame);
      };
      processFrame();
    }

    start().catch(err => console.error("Camera error:", err));

    // --- 3. ANIMATION LOOP ---
    function animate() {
      requestAnimationFrame(animate);
      if (monkey) {
        // Applying the movement with smooth LERP
        monkey.rotation.y = THREE.MathUtils.lerp(monkey.rotation.y, faceRotation.y, 0.1);
        monkey.rotation.x = THREE.MathUtils.lerp(monkey.rotation.x, faceRotation.x, 0.1);

        // Breathing/Floating
        monkey.position.y = (Math.sin(Date.now() * 0.001) * 0.05) - 0.1;
      }
      renderer.render(scene, camera);
    }
    animate();

    window.addEventListener("resize", () => {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });
  </script>
</body>

</html>